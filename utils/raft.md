# Raft 一致性算法详解

## 一、概述
Raft 是一种为分布式系统设计的强一致性、易理解的共识算法，通过简化选举和日志复制流程，解决多节点间数据一致性问题。

## 二、核心机制
### 2.1 角色划分
- **Leader（领导者）**：唯一处理客户端写请求，负责日志复制与同步（心跳机制维持权威）。
- **Follower（跟随者）**：被动接收Leader日志同步，超时未收到心跳则转为Candidate（候选者）。
- **Candidate（候选者）**：触发选举流程，争取多数派投票成为新Leader。

### 2.2 选举过程
- **心跳超时**：Follower若超过选举超时时间（150-300ms）未收到Leader心跳，转为Candidate并发起选举。
- **投票规则**：Candidate向所有节点发送RequestVote RPC，需获得多数派（n/2+1）投票才能成为Leader。
- **任期（Term）**：全局递增的逻辑时钟，用于处理旧Leader失效（如网络分区后旧Leader恢复）。

### 2.3 日志复制
- **日志条目**：客户端请求被封装为带Term和索引的日志条目，由Leader通过AppendEntries RPC同步至Follower。
- **多数派确认**：当多数Follower成功复制日志后，Leader标记该日志为“已提交”，并应用到状态机。
- **日志一致性**：通过Term和索引匹配原则（Follower拒绝不符合前一条日志Term/索引的条目）保证全集群日志一致。

### 2.4 优化实践
- **日志压缩（Log Compaction）**：长期运行的Raft集群会积累大量日志，导致存储和性能问题。通过快照（Snapshot）机制，将状态机的当前状态保存为快照，仅保留快照之后的日志条目。快照由Leader触发，Follower在日志差距过大时可请求Leader发送快照以快速同步。
- **流水线复制（Pipelining）**：传统日志复制需等待前一条日志被多数派确认后再发送下一条，导致延迟较高。通过允许Leader并行发送多条日志条目（限制未确认日志的最大数量），减少网络往返时间（RTT）对性能的影响，提升复制效率。

## 三、关键流程
### 3.1 选举触发条件
- Leader故障（网络分区或宕机）导致Follower心跳超时。
- 集群初始化时无Leader存在。

### 3.2 日志提交规则
- 仅Leader可提交日志，且需满足多数派复制。
- 提交当前Term的日志时，可连带提交之前Term的日志（通过索引连续性保证）。
- 避免旧Term日志覆盖：新Leader通过强制Follower复制自身日志（可能截断冲突条目）确保一致性。

## 四、应用场景
- **分布式存储系统**：如etcd（微服务注册中心）、Consul（服务发现）通过Raft保证集群数据强一致。
- **数据库集群**：TiDB（分布式数据库）使用Raft实现多副本数据同步，避免单点故障。
- **高可用中间件**：Kafka Controller选举、Redis Sentinel主从切换（扩展版Raft）中用于协调节点状态。

> 注：本文档可作为分布式系统学习或面试准备的核心参考，重点掌握角色状态转换、选举多数派原则及日志复制一致性保证机制。