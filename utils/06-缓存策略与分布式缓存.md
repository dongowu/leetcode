# 缓存策略与分布式缓存

## 背景
随着互联网业务规模的扩大，数据库访问压力不断增加，系统响应时间变长，用户体验下降。缓存技术通过将热点数据存储在内存中，减少数据库访问，提高系统响应速度。在分布式环境下，单机缓存无法满足高可用和大容量需求，分布式缓存应运而生。分布式缓存通过数据分片、复制等技术，实现了高性能、高可用、可扩展的缓存服务，成为现代互联网架构的核心组件。

## 核心原理

### 1. 缓存基本原理

#### 缓存命中率
- **定义**：缓存命中次数与总请求次数的比率
- **影响因素**：缓存容量、缓存策略、数据访问模式
- **优化方法**：预热缓存、调整过期时间、使用多级缓存
- **计算公式**：命中率 = 命中次数 / (命中次数 + 未命中次数)

#### 缓存淘汰策略
- **LRU (Least Recently Used)**：淘汰最近最少使用的数据
```go
type LRUCache struct {
    capacity int
    cache    map[string]*list.Element
    list     *list.List
}

type entry struct {
    key   string
    value interface{}
}

func NewLRUCache(capacity int) *LRUCache {
    return &LRUCache{
        capacity: capacity,
        cache:    make(map[string]*list.Element),
        list:     list.New(),
    }
}

func (c *LRUCache) Get(key string) (interface{}, bool) {
    if elem, ok := c.cache[key]; ok {
        c.list.MoveToFront(elem)
        return elem.Value.(*entry).value, true
    }
    return nil, false
}

func (c *LRUCache) Put(key string, value interface{}) {
    if elem, ok := c.cache[key]; ok {
        c.list.MoveToFront(elem)
        elem.Value.(*entry).value = value
        return
    }
    
    if c.list.Len() >= c.capacity {
        oldest := c.list.Back()
        if oldest != nil {
            c.list.Remove(oldest)
            delete(c.cache, oldest.Value.(*entry).key)
        }
    }
    
    elem := c.list.PushFront(&entry{key, value})
    c.cache[key] = elem
}
```

- **LFU (Least Frequently Used)**：淘汰访问频率最低的数据
- **FIFO (First In First Out)**：淘汰最先进入缓存的数据
- **TTL (Time To Live)**：基于过期时间淘汰数据
- **Random**：随机淘汰数据

#### 缓存更新策略
- **Cache-Aside**：先更新数据库，再删除缓存
```go
func UpdateData(key string, value interface{}) error {
    // 1. 更新数据库
    err := db.Update(key, value)
    if err != nil {
        return err
    }
    
    // 2. 删除缓存
    cache.Delete(key)
    return nil
}

func GetData(key string) (interface{}, error) {
    // 1. 查询缓存
    value, found := cache.Get(key)
    if found {
        return value, nil
    }
    
    // 2. 缓存未命中，查询数据库
    value, err := db.Get(key)
    if err != nil {
        return nil, err
    }
    
    // 3. 更新缓存
    cache.Set(key, value)
    return value, nil
}
```

- **Write-Through**：同时更新缓存和数据库
- **Write-Behind**：先更新缓存，异步更新数据库
- **Refresh-Ahead**：在数据过期前主动刷新缓存

### 2. 分布式缓存架构

#### 客户端分片
```go
type ShardedCache struct {
    shards    []*Cache
    shardMask uint32
}

func NewShardedCache(shardCount int) *ShardedCache {
    shards := make([]*Cache, shardCount)
    for i := 0; i < shardCount; i++ {
        shards[i] = NewCache()
    }
    
    return &ShardedCache{
        shards:    shards,
        shardMask: uint32(shardCount - 1),
    }
}

func (c *ShardedCache) getShard(key string) *Cache {
    hash := crc32.ChecksumIEEE([]byte(key))
    return c.shards[hash&c.shardMask]
}

func (c *ShardedCache) Get(key string) (interface{}, bool) {
    return c.getShard(key).Get(key)
}

func (c *ShardedCache) Set(key string, value interface{}) {
    c.getShard(key).Set(key, value)
}
```

#### 一致性哈希
```go
type ConsistentHash struct {
    hashRing     map[uint32]string
    sortedHashes []uint32
    replicas     int
    nodes        map[string]bool
}

func NewConsistentHash(replicas int) *ConsistentHash {
    return &ConsistentHash{
        hashRing:     make(map[uint32]string),
        sortedHashes: []uint32{},
        replicas:     replicas,
        nodes:        make(map[string]bool),
    }
}

func (c *ConsistentHash) Add(node string) {
    if _, exists := c.nodes[node]; exists {
        return
    }
    
    c.nodes[node] = true
    
    for i := 0; i < c.replicas; i++ {
        hash := c.hashKey(fmt.Sprintf("%s-%d", node, i))
        c.hashRing[hash] = node
        c.sortedHashes = append(c.sortedHashes, hash)
    }
    
    sort.Slice(c.sortedHashes, func(i, j int) bool {
        return c.sortedHashes[i] < c.sortedHashes[j]
    })
}

func (c *ConsistentHash) Remove(node string) {
    if _, exists := c.nodes[node]; !exists {
        return
    }
    
    delete(c.nodes, node)
    
    for i := 0; i < c.replicas; i++ {
        hash := c.hashKey(fmt.Sprintf("%s-%d", node, i))
        delete(c.hashRing, hash)
    }
    
    c.updateSortedHashes()
}

func (c *ConsistentHash) updateSortedHashes() {
    c.sortedHashes = []uint32{}
    for hash := range c.hashRing {
        c.sortedHashes = append(c.sortedHashes, hash)
    }
    sort.Slice(c.sortedHashes, func(i, j int) bool {
        return c.sortedHashes[i] < c.sortedHashes[j]
    })
}

func (c *ConsistentHash) Get(key string) string {
    if len(c.sortedHashes) == 0 {
        return ""
    }
    
    hash := c.hashKey(key)
    
    // 二分查找大于等于hash的最小值
    idx := sort.Search(len(c.sortedHashes), func(i int) bool {
        return c.sortedHashes[i] >= hash
    })
    
    if idx == len(c.sortedHashes) {
        idx = 0
    }
    
    return c.hashRing[c.sortedHashes[idx]]
}

func (c *ConsistentHash) hashKey(key string) uint32 {
    h := fnv.New32a()
    h.Write([]byte(key))
    return h.Sum32()
}
```

#### 主从复制
```go
type ReplicatedCache struct {
    master  *Cache
    slaves  []*Cache
    options ReplicationOptions
}

type ReplicationOptions struct {
    SyncWrites bool
    ReadPolicy ReadPolicy
}

type ReadPolicy int

const (
    ReadFromMaster ReadPolicy = iota
    ReadFromSlave
    ReadFromRandom
)

func (c *ReplicatedCache) Set(key string, value interface{}) error {
    // 写入主缓存
    c.master.Set(key, value)
    
    // 同步写入从缓存
    if c.options.SyncWrites {
        for _, slave := range c.slaves {
            slave.Set(key, value)
        }
    } else {
        // 异步写入从缓存
        go func() {
            for _, slave := range c.slaves {
                slave.Set(key, value)
            }
        }()
    }
    
    return nil
}

func (c *ReplicatedCache) Get(key string) (interface{}, bool) {
    switch c.options.ReadPolicy {
    case ReadFromMaster:
        return c.master.Get(key)
    case ReadFromSlave:
        if len(c.slaves) > 0 {
            idx := rand.Intn(len(c.slaves))
            return c.slaves[idx].Get(key)
        }
        return c.master.Get(key)
    case ReadFromRandom:
        allCaches := append([]*Cache{c.master}, c.slaves...)
        idx := rand.Intn(len(allCaches))
        return allCaches[idx].Get(key)
    default:
        return c.master.Get(key)
    }
}
```

## 技术亮点

### 1. 多级缓存架构
- **浏览器缓存**：减少网络请求，提高用户体验
- **CDN缓存**：分布式内容分发，降低源站压力
- **接入层缓存**：API网关、反向代理缓存
- **应用层缓存**：本地缓存、进程内缓存
- **分布式缓存**：Redis、Memcached等
- **数据库缓存**：查询缓存、缓冲池

### 2. 缓存预热与更新
- **启动预热**：系统启动时主动加载热点数据
- **定时刷新**：周期性更新过期数据
- **异步加载**：后台线程异步加载数据
- **事件驱动**：数据变更时触发缓存更新
- **批量操作**：批量获取和更新缓存数据

### 3. 缓存监控与优化
- **命中率监控**：实时监控缓存命中率
- **容量监控**：监控缓存内存使用情况
- **延迟监控**：监控缓存访问延迟
- **热点分析**：识别热点数据，优化缓存策略
- **异常检测**：检测缓存穿透、缓存雪崩等异常

## 技术分析

### 1. Redis分布式缓存

#### 数据结构
- **String**：简单键值对，适用于计数器、分布式锁等
- **Hash**：哈希表，适用于存储对象
- **List**：链表，适用于消息队列、最新数据列表
- **Set**：集合，适用于去重、交集运算
- **Sorted Set**：有序集合，适用于排行榜、优先级队列
- **Bitmap**：位图，适用于布隆过滤器、用户活跃度统计
- **HyperLogLog**：基数统计，适用于UV统计
- **Geo**：地理位置，适用于附近的人、地点

#### 持久化机制
- **RDB**：按时间点快照，适用于备份和恢复
```
save 900 1      # 900秒内至少有1个key变更，则触发保存
save 300 10     # 300秒内至少有10个key变更，则触发保存
save 60 10000   # 60秒内至少有10000个key变更，则触发保存
```

- **AOF**：记录写操作日志，适用于数据安全性要求高的场景
```
appendonly yes
appendfsync everysec  # 每秒同步一次AOF文件
```

- **混合持久化**：结合RDB和AOF的优点
```
aof-use-rdb-preamble yes
```

#### 集群模式
- **主从复制**：读写分离，提高读性能
```
slaveof <masterip> <masterport>
```

- **哨兵模式**：自动故障转移，提高可用性
```
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 30000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1
```

- **Cluster模式**：数据自动分片，支持水平扩展
```
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 15000
```

### 2. 缓存常见问题

#### 缓存穿透
- **问题**：查询不存在的数据，绕过缓存直接查询数据库
- **解决方案**：
  - 布隆过滤器：快速判断数据是否存在
  - 缓存空值：对不存在的数据也进行缓存
  - 请求限流：限制单个用户的请求频率

```go
func GetData(key string) (interface{}, error) {
    // 1. 查询缓存
    value, found := cache.Get(key)
    if found {
        if value == nil {
            return nil, errors.New("data not found")
        }
        return value, nil
    }
    
    // 2. 查询数据库
    value, err := db.Get(key)
    if err != nil {
        if errors.Is(err, sql.ErrNoRows) {
            // 缓存空值，设置较短的过期时间
            cache.SetWithExpire(key, nil, 5*time.Minute)
            return nil, errors.New("data not found")
        }
        return nil, err
    }
    
    // 3. 更新缓存
    cache.Set(key, value)
    return value, nil
}
```

#### 缓存击穿
- **问题**：热点数据过期，大量请求同时查询数据库
- **解决方案**：
  - 互斥锁：只允许一个请求更新缓存
  - 热点数据永不过期：对热点数据设置较长的过期时间
  - 提前更新：在数据过期前异步更新缓存

```go
var mutex sync.Mutex

func GetData(key string) (interface{}, error) {
    // 1. 查询缓存
    value, found := cache.Get(key)
    if found {
        return value, nil
    }
    
    // 2. 加锁，防止缓存击穿
    mutex.Lock()
    defer mutex.Unlock()
    
    // 3. 再次查询缓存，可能已被其他协程更新
    value, found = cache.Get(key)
    if found {
        return value, nil
    }
    
    // 4. 查询数据库
    value, err := db.Get(key)
    if err != nil {
        return nil, err
    }
    
    // 5. 更新缓存
    cache.Set(key, value)
    return value, nil
}
```

#### 缓存雪崩
- **问题**：大量缓存同时过期，导致数据库压力骤增
- **解决方案**：
  - 过期时间随机化：避免同时过期
  - 多级缓存：构建多级缓存架构
  - 熔断降级：当系统负载过高时，启用降级策略
  - 集群化部署：提高缓存服务的可用性

```go
func SetWithRandomExpire(key string, value interface{}) {
    // 基础过期时间
    baseExpire := 3600 * time.Second
    
    // 随机增加0-600秒的过期时间
    randomExpire := time.Duration(rand.Intn(600)) * time.Second
    
    // 设置缓存，带随机过期时间
    cache.SetWithExpire(key, value, baseExpire+randomExpire)
}
```

#### 缓存一致性
- **问题**：缓存与数据库数据不一致
- **解决方案**：
  - 更新数据库 + 删除缓存：先更新数据库，再删除缓存
  - 更新数据库 + 更新缓存：先更新数据库，再更新缓存
  - 消息队列：通过消息队列保证更新顺序
  - 读写锁：对同一数据的读写加锁

```go
func UpdateData(key string, value interface{}) error {
    // 1. 更新数据库
    err := db.Update(key, value)
    if err != nil {
        return err
    }
    
    // 2. 发送消息到队列，异步更新缓存
    message := UpdateMessage{
        Key:   key,
        Value: value,
        Time:  time.Now(),
    }
    
    err = queue.Publish("cache.update", message)
    if err != nil {
        log.Printf("Failed to publish cache update message: %v", err)
    }
    
    return nil
}

// 消费者处理缓存更新
func processCacheUpdate() {
    for message := range queue.Subscribe("cache.update") {
        updateMsg := message.(UpdateMessage)
        
        // 更新缓存
        cache.Set(updateMsg.Key, updateMsg.Value)
        log.Printf("Cache updated for key %s", updateMsg.Key)
    }
}
```

## 技术组件详解

### 1. Redis核心组件

#### Redis Sentinel
```go
type SentinelClient struct {
    client *redis.Client
    pool   *redis.Pool
}

func NewSentinelClient(sentinelAddrs []string, masterName string) (*SentinelClient, error) {
    sentinel := &redis.Sentinel{
        Addrs:      sentinelAddrs,
        MasterName: masterName,
        Dial: func(addr string) (redis.Conn, error) {
            return redis.Dial("tcp", addr)
        },
    }
    
    pool := &redis.Pool{
        MaxIdle:     10,
        MaxActive:   100,
        IdleTimeout: 240 * time.Second,
        Dial: func() (redis.Conn, error) {
            masterAddr, err := sentinel.MasterAddr()
            if err != nil {
                return nil, err
            }
            return redis.Dial("tcp", masterAddr)
        },
        TestOnBorrow: func(c redis.Conn, t time.Time) error {
            if time.Since(t) < time.Minute {
                return nil
            }
            _, err := c.Do("PING")
            return err
        },
    }
    
    return &SentinelClient{
        pool: pool,
    }, nil
}

func (c *SentinelClient) Get(key string) (string, error) {
    conn := c.pool.Get()
    defer conn.Close()
    
    return redis.String(conn.Do("GET", key))
}

func (c *SentinelClient) Set(key, value string) error {
    conn := c.pool.Get()
    defer conn.Close()
    
    _, err := conn.Do("SET", key, value)
    return err
}
```

#### Redis Cluster
```go
type ClusterClient struct {
    client *redis.ClusterClient
}

func NewClusterClient(addrs []string) (*ClusterClient, error) {
    client := redis.NewClusterClient(&redis.ClusterOptions{
        Addrs:    addrs,
        PoolSize: 50,
    })
    
    // 测试连接
    if err := client.Ping().Err(); err != nil {
        return nil, err
    }
    
    return &ClusterClient{
        client: client,
    }, nil
}

func (c *ClusterClient) Get(key string) (string, error) {
    return c.client.Get(key).Result()
}

func (c *ClusterClient) Set(key, value string) error {
    return c.client.Set(key, value, 0).Err()
}

func (c *ClusterClient) HGetAll(key string) (map[string]string, error) {
    return c.client.HGetAll(key).Result()
}

func (c *ClusterClient) Pipeline() redis.Pipeliner {
    return c.client.Pipeline()
}
```

### 2. 本地缓存组件

#### 进程内缓存
```go
type LocalCache struct {
    data     map[string]cacheItem
    mutex    sync.RWMutex
    janitor  *time.Ticker
    stopChan chan struct{}
}

type cacheItem struct {
    value      interface{}
    expiration time.Time
}

func NewLocalCache(cleanupInterval time.Duration) *LocalCache {
    cache := &LocalCache{
        data:     make(map[string]cacheItem),
        janitor:  time.NewTicker(cleanupInterval),
        stopChan: make(chan struct{}),
    }
    
    go cache.janitorRun()
    
    return cache
}

func (c *LocalCache) janitorRun() {
    for {
        select {
        case <-c.janitor.C:
            c.deleteExpired()
        case <-c.stopChan:
            c.janitor.Stop()
            return
        }
    }
}

func (c *LocalCache) deleteExpired() {
    now := time.Now()
    
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    for key, item := range c.data {
        if !item.expiration.IsZero() && item.expiration.Before(now) {
            delete(c.data, key)
        }
    }
}

func (c *LocalCache) Set(key string, value interface{}, ttl time.Duration) {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    var expiration time.Time
    if ttl > 0 {
        expiration = time.Now().Add(ttl)
    }
    
    c.data[key] = cacheItem{
        value:      value,
        expiration: expiration,
    }
}

func (c *LocalCache) Get(key string) (interface{}, bool) {
    c.mutex.RLock()
    defer c.mutex.RUnlock()
    
    item, found := c.data[key]
    if !found {
        return nil, false
    }
    
    if !item.expiration.IsZero() && item.expiration.Before(time.Now()) {
        return nil, false
    }
    
    return item.value, true
}

func (c *LocalCache) Delete(key string) {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    delete(c.data, key)
}

func (c *LocalCache) Close() {
    close(c.stopChan)
}
```

#### 多级缓存
```go
type MultiLevelCache struct {
    l1     Cache // 本地缓存
    l2     Cache // 分布式缓存
    options MultiLevelOptions
}

type MultiLevelOptions struct {
    WriteL1OnMiss bool
    WriteL2OnMiss bool
    WriteL1OnPut  bool
    WriteL2OnPut  bool
}

func NewMultiLevelCache(l1, l2 Cache, options MultiLevelOptions) *MultiLevelCache {
    return &MultiLevelCache{
        l1:      l1,
        l2:      l2,
        options: options,
    }
}

func (c *MultiLevelCache) Get(key string) (interface{}, bool) {
    // 查询L1缓存
    value, found := c.l1.Get(key)
    if found {
        return value, true
    }
    
    // L1未命中，查询L2缓存
    value, found = c.l2.Get(key)
    if found && c.options.WriteL1OnMiss {
        // 回填L1缓存
        c.l1.Set(key, value)
    }
    
    return value, found
}

func (c *MultiLevelCache) Set(key string, value interface{}) {
    if c.options.WriteL1OnPut {
        c.l1.Set(key, value)
    }
    
    if c.options.WriteL2OnPut {
        c.l2.Set(key, value)
    }
}

func (c *MultiLevelCache) Delete(key string) {
    c.l1.Delete(key)
    c.l2.Delete(key)
}
```

## 使用场景

### 1. 数据库查询缓存
```go
func GetUserById(id string) (*User, error) {
    cacheKey := fmt.Sprintf("user:%s", id)
    
    // 查询缓存
    if cachedUser, found := cache.Get(cacheKey); found {
        return cachedUser.(*User), nil
    }
    
    // 缓存未命中，查询数据库
    user, err := db.QueryUserById(id)
    if err != nil {
        return nil, err
    }
    
    // 更新缓存，设置过期时间
    cache.SetWithExpire(cacheKey, user, 30*time.Minute)
    
    return user, nil
}
```

### 2. 接口限流
```go
func RateLimiter(key string, limit int, period time.Duration) bool {
    cacheKey := fmt.Sprintf("ratelimit:%s", key)
    
    // 使用Redis的INCR命令原子递增计数器
    count, err := redisClient.Incr(cacheKey).Result()
    if err != nil {
        log.Printf("Rate limiter error: %v", err)
        return true // 错误情况下允许请求通过
    }
    
    // 如果是第一次请求，设置过期时间
    if count == 1 {
        redisClient.Expire(cacheKey, period)
    }
    
    // 判断是否超过限制
    return count <= int64(limit)
}

func RateLimitMiddleware(limit int, period time.Duration) gin.HandlerFunc {
    return func(c *gin.Context) {
        // 使用IP或用户ID作为限流键
        key := c.ClientIP()
        if userId, exists := c.Get("userId"); exists {
            key = userId.(string)
        }
        
        // 检查是否超过限制
        if !RateLimiter(key, limit, period) {
            c.JSON(http.StatusTooManyRequests, gin.H{
                "error": "Rate limit exceeded",
            })
            c.Abort()
            return
        }
        
        c.Next()
    }
}
```

### 3. 会话存储
```go
type SessionStore struct {
    redisClient *redis.Client
    prefix      string
    ttl         time.Duration
}

func NewSessionStore(redisClient *redis.Client) *SessionStore {
    return &SessionStore{
        redisClient: redisClient,
        prefix:      "session:",
        ttl:         24 * time.Hour,
    }
}

func (s *SessionStore) Get(sessionID string) (map[string]interface{}, error) {
    key := s.prefix + sessionID
    
    // 获取会话数据
    data, err := s.redisClient.Get(key).Result()
    if err != nil {
        if err == redis.Nil {
            return make(map[string]interface{}), nil
        }
        return nil, err
    }
    
    // 反序列化会话数据
    var session map[string]interface{}
    if err := json.Unmarshal([]byte(data), &session); err != nil {
        return nil, err
    }
    
    // 刷新过期时间
    s.redisClient.Expire(key, s.ttl)
    
    return session, nil
}

func (s *SessionStore) Set(sessionID string, data map[string]interface{}) error {
    key := s.prefix + sessionID
    
    // 序列化会话数据
    jsonData, err := json.Marshal(data)
    if err != nil {
        return err
    }
    
    // 存储会话数据并设置过期时间
    return s.redisClient.Set(key, jsonData, s.ttl).Err()
}

func (s *SessionStore) Delete(sessionID string) error {
    key := s.prefix + sessionID
    return s.redisClient.Del(key).Err()
}
```

### 4. 分布式锁
```go
type RedisLock struct {
    redisClient *redis.Client
    key         string
    value       string
    ttl         time.Duration
}

func NewRedisLock(redisClient *redis.Client, key string) *RedisLock {
    return &RedisLock{
        redisClient: redisClient,
        key:         "lock:" + key,
        value:       uuid.New().String(),
        ttl:         10 * time.Second,
    }
}

func (l *RedisLock) Acquire() (bool, error) {
    // 使用SET NX命令尝试获取锁
    result, err := l.redisClient.SetNX(l.key, l.value, l.ttl).Result()
    if err != nil {
        return false, err
    }
    
    return result, nil
}

func (l *RedisLock) Release() error {
    // 使用Lua脚本确保只释放自己的锁
    script := `
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
    `
    
    _, err := l.redisClient.Eval(script, []string{l.key}, l.value).Result()
    return err
}

func (l *RedisLock) Extend(ttl time.Duration) (bool, error) {
    // 使用Lua脚本延长锁的过期时间
    script := `
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("pexpire", KEYS[1], ARGV[2])
        else
            return 0
        end
    `
    
    result, err := l.redisClient.Eval(script, []string{l.key}, l.value, int64(ttl/time.Millisecond)).Result()
    if err != nil {
        return false, err
    }
    
    return result.(int64) == 1, nil
}
```

## 思考空间

### 1. 缓存设计原则
- **缓存粒度**：缓存的数据粒度应该如何选择？
- **缓存策略**：不同场景下应该选择哪种缓存策略？
- **缓存一致性**：如何平衡缓存一致性和性能？
- **缓存穿透防护**：如何设计更高效的缓存穿透防护机制？

### 2. 缓存架构演进
- **单机到分布式**：如何平滑迁移从单机缓存到分布式缓存？
- **多级缓存**：如何设计多级缓存架构？
- **全局缓存**：如何设计全局一致的缓存系统？
- **异地多活**：如何处理异地多活架构下的缓存同步问题？

### 3. 缓存与存储融合
- **读写分离**：缓存如何与读写分离架构结合？
- **数据分片**：缓存分片与数据库分片如何协同？
- **冷热分离**：如何实现数据冷热分离？
- **存储计算分离**：缓存在存储计算分离架构中的角色？

## 面试常见问题

### 1. 基础概念
**Q: 什么是缓存穿透、缓存击穿和缓存雪崩？如何解决？**

A: 
- **缓存穿透**：指查询不存在的数据，绕过缓存直接查询数据库。
  - 解决方案：布隆过滤器、缓存空值、请求限流

- **缓存击穿**：指热点数据过期，大量请求同时查询数据库。
  - 解决方案：互斥锁、热点数据永不过期、提前更新

- **缓存雪崩**：指大量缓存同时过期，导致数据库压力骤增。
  - 解决方案：过期时间随机化、多级缓存、熔断降级、集群化部署

**Q: Redis和Memcached的区别？**

A: 
- **数据结构**：Redis支持多种数据结构（String、Hash、List、Set、Sorted Set等），Memcached只支持简单的key-value存储
- **持久化**：Redis支持RDB和AOF持久化，Memcached不支持持久化
- **集群模式**：Redis原生支持集群模式，Memcached需要客户端实现分片
- **内存管理**：Redis使用自己的内存管理机制，Memcached使用slab allocation机制
- **事务支持**：Redis支持事务，Memcached不支持事务
- **性能**：Memcached在单纯的key-value存储上性能略高，Redis在复杂数据结构上有优势

### 2. 技术实现
**Q: Redis的持久化机制有哪些？各有什么优缺点？**

A: Redis有两种持久化机制：

- **RDB（Redis Database）**：
  - 原理：按时间点将数据快照写入磁盘
  - 优点：文件紧凑，恢复速度快，适合备份
  - 缺点：可能丢失最后一次快照后的数据，快照时可能阻塞服务

- **AOF（Append Only File）**：
  - 原理：记录所有写操作命令，重启时重放恢复数据
  - 优点：数据安全性高，支持秒级同步
  - 缺点：文件体积大，恢复速度慢

- **混合持久化**：
  - 原理：结合RDB和AOF的优点，先将数据以RDB方式写入，再将后续命令以AOF方式追加
  - 优点：兼顾数据安全性和恢复速度
  - 缺点：实现复杂，兼容性问题

**Q: Redis的集群方案有哪些？如何选择？**

A: Redis的集群方案：

- **主从复制**：
  - 架构：一主多从，主写从读
  - 优点：配置简单，读写分离提高性能
  - 缺点：主节点单点故障，无自动故障转移
  - 适用场景：读多写少，对可用性要求不高

- **哨兵模式**：
  - 架构：在主从基础上增加哨兵监控，自动故障转移
  - 优点：高可用，自动故障恢复
  - 缺点：不支持水平扩展，配置相对复杂
  - 适用场景：对可用性要求高，数据量不是特别大

- **Cluster模式**：
  - 架构：数据自动分片，每个节点存储部分数据
  - 优点：支持水平扩展，高可用，自动分片
  - 缺点：客户端实现复杂，事务支持有限
  - 适用场景：数据量大，需要水平扩展

### 3. 架构设计
**Q: 如何设计一个高性能的缓存系统？**

A: 设计高性能缓存系统的关键点：

- **多级缓存**：
  - 本地缓存（进程内缓存）：最快，但容量有限
  - 分布式缓存（Redis/Memcached）：容量大，但有网络开销
  - 数据库缓存：最后一道防线

- **缓存策略**：
  - 读写策略：Cache-Aside、Write-Through、Write-Behind
  - 淘汰策略：LRU、LFU、FIFO等
  - 过期策略：TTL、惰性删除、定期删除

- **数据分片**：
  - 一致性哈希：减少节点变化时的数据迁移
  - 虚拟节点：均衡数据分布

- **高可用设计**：
  - 主从复制：数据备份
  - 故障转移：自动切换
  - 集群化：避免单点故障

- **监控与优化**：
  - 命中率监控：实时监控缓存效率
  - 容量规划：根据业务增长预估容量
  - 热点分析：识别并优化热点数据

**Q: 如何保证缓存与数据库的一致性？**

A: 缓存与数据库一致性的保证方法：

- **更新策略**：
  - 先更新数据库，再删除缓存：最常用的方式，一致性较好
  - 先删除缓存，再更新数据库：可能导致读取旧数据
  - 先更新数据库，再更新缓存：双写不一致问题

- **一致性增强**：
  - 延迟双删：更新数据库后删除缓存，再延迟一段时间后再次删除缓存
  - 消息队列：通过消息队列保证更新顺序和可靠性
  - 分布式事务：强一致性保证，但性能开销大

- **最终一致性**：
  - 定时任务：定期同步数据库和缓存
  - 版本号/时间戳：通过版本控制解决并发更新问题
  - 读写锁：对同一数据的读写加锁

### 4. 性能优化
**Q: Redis性能优化的方法有哪些？**

A: Redis性能优化方法：

- **内存优化**：
  - 合理设置maxmemory和淘汰策略
  - 使用压缩数据结构（如ziplist）
  - 设置合理的过期时间
  - 避免大key

- **命令优化**：
  - 使用批量命令（mget/mset）代替单个命令
  - 使用pipeline减少网络往返
  - 避免使用耗时命令（如keys）
  - 使用scan代替keys

- **连接优化**：
  - 使用连接池
  - 合理设置连接数
  - 复用连接

- **持久化优化**：
  - 使用混合持久化
  - 调整RDB保存频率
  - AOF重写参数优化

- **集群优化**：
  - 合理的数据分片
  - 读写分离
  - 副本集配置

**Q: 如何处理缓存预热和冷启动问题？**

A: 缓存预热和冷启动处理方法：

- **缓存预热**：
  - 系统启动时主动加载热点数据
  - 脚本预加载：编写脚本提前加载数据
  - 分批加载：避免一次性加载过多数据
  - 优先级加载：先加载核心业务数据

- **冷启动优化**：
  - 降级策略：缓存未命中时返回默认值
  - 限流措施：控制数据库访问频率
  - 异步加载：后台线程异步加载缓存
  - 多级缓存：本地缓存作为第一道防线

### 5. 故障处理
**Q: Redis常见故障及处理方法？**

A: Redis常见故障及处理：

- **内存溢出**：
  - 症状：Redis无法写入新数据，报OOM错误
  - 处理：增加内存、调整maxmemory、优化数据结构、清理大key

- **高延迟**：
  - 症状：Redis响应时间变长
  - 处理：排查慢查询、避免使用耗时命令、调整内存配置、检查网络问题

- **主从复制中断**：
  - 症状：从节点无法同步主节点数据
  - 处理：检查网络连接、调整复制缓冲区大小、重新建立复制

- **持久化失败**：
  - 症状：RDB或AOF文件无法生成或损坏
  - 处理：检查磁盘空间、调整持久化参数、修复AOF文件

- **集群节点失效**：
  - 症状：集群节点不可用，槽位分配异常
  - 处理：故障转移、手动重新分片、恢复节点

**Q: 如何监控和排查Redis性能问题？**

A: Redis性能监控和排查：

- **监控指标**：
  - 内存使用率：used_memory、used_memory_rss
  - 命令执行：instantaneous_ops_per_sec
  - 命中率：keyspace_hits、keyspace_misses
  - 连接数：connected_clients
  - 阻塞命令：blocked_clients

- **工具命令**：
  - INFO：获取Redis服务器的各种信息
  - SLOWLOG：查看慢查询日志
  - MONITOR：实时监控Redis执行的命令
  - CLIENT LIST：查看客户端连接信息
  - MEMORY DOCTOR：内存使用诊断

- **排查方法**：
  - 分析慢查询日志找出耗时命令
  - 使用SCAN扫描大key
  - 监控内存碎片率
  - 检查网络延迟
  - 分析客户端连接情况