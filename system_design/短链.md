# 短链系统设计

## 一、需求分析与范围界定

### 1.1 业务需求澄清

#### 功能性需求
- **核心功能**：将长URL转换为短URL，访问短URL时重定向到原始长URL
- **URL管理**：创建、查询、统计、过期管理
- **用户角色**：普通用户（使用短链）、注册用户（创建和管理短链）、管理员（系统管理）
- **业务流程**：
  1. 用户提交长URL获取短链
  2. 系统生成并返回短链
  3. 用户访问短链时重定向到原始URL
  4. 记录访问统计数据

#### 非功能性需求
- **性能指标**：
  - 短链生成响应时间：P99 < 100ms
  - 重定向响应时间：P99 < 50ms
  - 系统吞吐量：峰值 10,000 QPS
  - 可用性：99.99% SLA（每月允许4分钟故障时间）
- **安全性要求**：
  - 防止生成恶意链接
  - 访问控制（可选私有短链）
  - 防止URL遍历攻击
- **可扩展性**：支持水平扩展，应对流量增长

#### 约束条件
- **短链长度**：固定6-8个字符
- **有效期**：默认有效期1年，支持自定义
- **合规要求**：需过滤违规URL，支持内容审核
- **业务场景**：主要用于营销短信和社交媒体分享

### 1.2 规模评估

#### 用户规模
- DAU：1,000,000（日活用户）
- 并发用户：峰值10,000
- 增长预期：年增长率30%

#### 数据规模
- 短链创建量：100万/天（新增）
- 短链访问量：1000万/天（读取）
- 读写比例：10:1（读多写少）
- 数据增长：3.65亿条/年
- 单条数据大小：约1KB（包含元数据）
- 年数据存储：约365GB/年

#### 流量评估
- 平均QPS：
  - 写入：100万÷86400≈12 QPS
  - 读取：1000万÷86400≈116 QPS
- 峰值QPS（假设峰值是平均的5倍）：
  - 写入峰值：60 QPS
  - 读取峰值：580 QPS

### 1.3 关键指标定义
```
性能指标：
- 短链生成响应时间：P99 < 100ms
- 重定向响应时间：P99 < 50ms
- 系统吞吐量：峰值 10,000 QPS
- 可用性：99.99% SLA

容量指标：
- 存储容量：365GB/年
- 缓存容量：热点数据约30GB（近3个月活跃短链）
- 带宽需求：峰值约100Mbps
```

### 1.4 背景与业务价值
- **营销场景**：短信营销中字符数限制，短链可节省空间
- **用户体验**：社交媒体分享时，短链更美观易记
- **数据分析**：通过短链可以追踪点击率、用户来源等数据
- **A/B测试**：同一目标URL可生成多个短链，用于不同渠道效果对比

## 二、高层架构设计

### 2.1 架构模式选择

#### 微服务架构
- **选择理由**：短链系统功能边界清晰，可以按照业务功能拆分为独立服务
- **服务划分**：
  - 短链生成服务：负责生成短链
  - 重定向服务：负责短链访问重定向
  - 统计分析服务：负责收集和分析访问数据
  - 管理服务：负责短链管理和配置

#### 事件驱动架构
- **选择理由**：短链访问统计适合采用事件驱动模式，解耦访问和统计逻辑
- **实现方式**：
  - 访问事件发布到消息队列
  - 统计服务异步消费事件进行处理
  - 减少对主流程的影响

#### 无状态设计
- **选择理由**：便于水平扩展，提高系统可用性
- **实现方式**：
  - 服务无状态化，状态存储在外部存储系统
  - 支持多实例部署和负载均衡

### 2.2 核心组件识别

#### 接入层
- **负载均衡**：Nginx/LVS，分发流量到多个服务实例
- **API网关**：Kong/APISIX，提供认证、限流、路由等功能
- **CDN**：用于静态资源加速和全球访问加速

#### 业务层
- **短链生成服务**：生成短链，处理URL提交请求
- **重定向服务**：处理短链访问，执行重定向
- **统计分析服务**：收集和分析访问数据
- **管理服务**：提供短链管理和配置功能

#### 数据层
- **关系型数据库**：MySQL，存储短链映射关系
- **缓存**：Redis，缓存热点短链映射
- **消息队列**：Kafka，处理访问事件
- **时序数据库**：InfluxDB，存储访问统计数据

#### 基础设施层
- **监控系统**：Prometheus + Grafana，监控系统运行状态
- **日志系统**：ELK Stack，收集和分析日志
- **配置中心**：Nacos/Apollo，管理配置
- **服务注册与发现**：Consul/Etcd，服务注册和发现

### 2.3 技术栈选型

```
编程语言：
- Go：高并发性能好，适合短链重定向服务
- Java：生态丰富，适合管理和统计服务

数据存储：
- MySQL：主存储，存储短链映射关系
- Redis：缓存层，提高读取性能
- InfluxDB：时序数据，存储访问统计

消息队列：
- Kafka：高吞吐，适合处理大量访问事件

基础设施：
- Docker + Kubernetes：容器化部署和编排
- Prometheus + Grafana：监控和告警
- ELK Stack：日志收集和分析
```

### 2.4 架构图绘制

#### 系统架构图
```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│   用户请求   │────▶│  负载均衡   │────▶│   API网关   │
└─────────────┘     └─────────────┘     └──────┬──────┘
                                                │
                                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                           业务服务层                             │
│                                                                 │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐            │
│  │ 短链生成服务 │   │ 重定向服务  │   │ 统计分析服务 │            │
│  └──────┬──────┘   └──────┬──────┘   └──────┬──────┘            │
│         │                 │                 │                   │
│         ▼                 ▼                 ▼                   │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐            │
│  │  管理服务   │   │  审核服务   │   │  配置服务   │            │
│  └─────────────┘   └─────────────┘   └─────────────┘            │
└─────────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────────┐
│                           数据服务层                             │
│                                                                 │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐            │
│  │    MySQL    │   │    Redis    │   │    Kafka    │            │
│  └─────────────┘   └─────────────┘   └─────────────┘            │
│                                                                 │
│  ┌─────────────┐   ┌─────────────┐                              │
│  │  InfluxDB   │   │ ElasticSearch│                              │
│  └─────────────┘   └─────────────┘                              │
└─────────────────────────────────────────────────────────────────┘
```

#### 部署架构图
```
┌─────────────────────────────────────────────────────────────────┐
│                         Kubernetes集群                           │
│                                                                 │
│  ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐ │
│  │   生产环境      │   │   测试环境      │   │   开发环境      │ │
│  │                 │   │                 │   │                 │ │
│  │  ┌───────────┐  │   │  ┌───────────┐  │   │  ┌───────────┐  │ │
│  │  │ 短链服务  │  │   │  │ 短链服务  │  │   │  │ 短链服务  │  │ │
│  │  └───────────┘  │   │  └───────────┘  │   │  └───────────┘  │ │
│  │                 │   │                 │   │                 │ │
│  │  ┌───────────┐  │   │  ┌───────────┐  │   │  ┌───────────┐  │ │
│  │  │ 重定向服务 │  │   │  │ 重定向服务 │  │   │  │ 重定向服务 │  │ │
│  │  └───────────┘  │   │  └───────────┘  │   │  └───────────┘  │ │
│  │                 │   │                 │   │                 │ │
│  │  ┌───────────┐  │   │  ┌───────────┐  │   │  ┌───────────┐  │ │
│  │  │ 统计服务  │  │   │  │ 统计服务  │  │   │  │ 统计服务  │  │ │
│  │  └───────────┘  │   │  └───────────┘  │   │  └───────────┘  │ │
│  └─────────────────┘   └─────────────────┘   └─────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
```

## 三、详细设计

### 3.1 短链生成方案

#### 方案比较与选择

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|----------|
| **哈希算法(MurmurHash+Base62)** | 计算速度快，无需存储额外ID | 存在碰撞风险 | 中小规模系统 |
| **自增ID+Base62编码** | 唯一性保证，无碰撞 | 依赖数据库，性能瓶颈 | 一般规模系统 |
| **分布式ID生成(Snowflake)** | 分布式友好，高性能 | 依赖时钟，可能时钟回拨 | 大规模分布式系统 |
| **Redis计数器** | 高性能，实现简单 | 需要额外维护Redis | 高性能要求系统 |
| **UUID** | 生成简单，分布式友好 | ID长度过长，不适合短链 | 不适合短链系统 |

#### 推荐方案：混合策略

1. **主方案：自增ID段+Base62编码**
   - 使用数据库预分配ID段（每次获取1000个ID）
   - 应用内存中维护ID段，避免频繁访问数据库
   - 将ID转为Base62编码（6位字符，可表示56.8亿个短链）
   - Go实现示例：
   ```go
   // Base62字符集
   const base62Chars = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
   
   // 将ID转换为Base62编码的短链
   func encodeToBase62(id int64) string {
       if id == 0 {
           return string(base62Chars[0])
       }
       
       var result []byte
       base := int64(len(base62Chars))
       
       for id > 0 {
           result = append([]byte{base62Chars[id%base]}, result...)
           id = id / base
       }
       
       // 确保长度为6位，不足前面补0
       for len(result) < 6 {
           result = append([]byte{base62Chars[0]}, result...)
       }
       
       return string(result)
   }
   ```

2. **备选方案：哈希算法（处理自定义短链）**
   - 使用MurmurHash3算法计算URL的哈希值
   - 取哈希值的一部分转为Base62编码
   - 使用布隆过滤器快速检测可能的碰撞
   - 碰撞处理：添加计数器或时间戳重新哈希
   - Go实现示例：
   ```go
   import (
       "github.com/spaolacci/murmur3"
   )
   
   // 使用MurmurHash生成短链
   func generateShortLink(url string) string {
       // 添加时间戳减少碰撞
       data := url + strconv.FormatInt(time.Now().UnixNano(), 10)
       
       // 计算哈希值
       h := murmur3.New64()
       h.Write([]byte(data))
       id := h.Sum64()
       
       return encodeToBase62(int64(id % 56800235584)) // 确保在6位Base62范围内
   }
   ```

### 3.2 重定向策略

#### 301 vs 302 重定向
- **301永久重定向**：
  - 符合HTTP语义（短链到长链的映射通常不变）
  - 浏览器会缓存重定向结果，减少服务器负载
  - 缺点：无法统计点击数据，搜索引擎会直接展示原始URL

- **302临时重定向**：
  - 每次访问都会请求短链服务器
  - 可以统计点击数据，收集用户信息
  - 可以实现A/B测试、访问控制等高级功能

#### 最佳实践：使用302重定向
- 虽然从HTTP语义上看301更合适，但从业务需求看302更实用
- 可以收集统计数据，是短链服务的核心价值之一
- 可以实现更多高级功能：访问控制、地域重定向、A/B测试等



### 3.3 数据库设计

#### 数据模型设计

**短链映射表**
```sql
CREATE TABLE `t_short_url` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `short_url` varchar(8) NOT NULL DEFAULT '' COMMENT '短链接',
  `long_url` varchar(2048) NOT NULL DEFAULT '' COMMENT '原始链接',
  `user_id` bigint(20) unsigned DEFAULT NULL COMMENT '创建用户ID',
  `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `expired_at` timestamp NULL DEFAULT NULL COMMENT '过期时间',
  `status` tinyint(4) NOT NULL DEFAULT '1' COMMENT '状态 1:有效 2:无效',
  `source` varchar(64) DEFAULT NULL COMMENT '来源渠道',
  `description` varchar(256) DEFAULT NULL COMMENT '链接描述',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_short_url` (`short_url`),
  KEY `idx_user_id` (`user_id`),
  KEY `idx_created_at` (`created_at`),
  KEY `idx_expired_at` (`expired_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='短链接映射表';
```

**访问统计表**
```sql
CREATE TABLE `t_access_stats` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `short_url_id` bigint(20) unsigned NOT NULL COMMENT '短链ID',
  `short_url` varchar(8) NOT NULL COMMENT '短链接',
  `access_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '访问时间',
  `ip` varchar(64) DEFAULT NULL COMMENT '访问IP',
  `user_agent` varchar(512) DEFAULT NULL COMMENT '用户代理',
  `referer` varchar(1024) DEFAULT NULL COMMENT '来源页面',
  `device_type` varchar(32) DEFAULT NULL COMMENT '设备类型',
  `browser` varchar(64) DEFAULT NULL COMMENT '浏览器',
  `os` varchar(64) DEFAULT NULL COMMENT '操作系统',
  `country` varchar(64) DEFAULT NULL COMMENT '国家',
  `region` varchar(64) DEFAULT NULL COMMENT '地区',
  `city` varchar(64) DEFAULT NULL COMMENT '城市',
  PRIMARY KEY (`id`),
  KEY `idx_short_url_id` (`short_url_id`),
  KEY `idx_short_url` (`short_url`),
  KEY `idx_access_time` (`access_time`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='访问统计表';
```

**统计汇总表**
```sql
CREATE TABLE `t_stats_summary` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `short_url_id` bigint(20) unsigned NOT NULL COMMENT '短链ID',
  `short_url` varchar(8) NOT NULL COMMENT '短链接',
  `date` date NOT NULL COMMENT '统计日期',
  `pv` int(11) NOT NULL DEFAULT '0' COMMENT '页面浏览量',
  `uv` int(11) NOT NULL DEFAULT '0' COMMENT '独立访客数',
  `ip_count` int(11) NOT NULL DEFAULT '0' COMMENT 'IP数',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_url_date` (`short_url`, `date`),
  KEY `idx_date` (`date`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='统计汇总表';
```

#### 分库分表策略

**水平分表策略**

1. **按短链前缀分表**
   - 将短链按首字符分为多张表（如62张表对应Base62字符集）
   - 优点：分布均匀，查询路由简单
   - 缺点：扩展性有限，最多62张表

2. **按短链哈希取模分表**
   - 对短链进行哈希计算，然后对表数量取模
   - 优点：分布均匀，可以支持更多分表数量
   - 缺点：增加表数量需要数据迁移

3. **按ID范围分表**
   - 按照ID范围进行分表，如每1000万条数据一张表
   - 优点：新数据写入集中，历史数据查询性能稳定
   - 缺点：热点数据可能集中在最新表

**推荐方案：混合策略**

- 短链映射表：按短链哈希取模分表（16或32张表）
- 访问统计表：按时间范围分表（每月或每周一张表）
- 统计汇总表：按时间范围分表（每年一张表）

**分表实现示例（Go）**
```go
type ShardingStrategy interface {
    GetTableName(shortURL string) string
}

// 按短链哈希取模分表
type HashModSharding struct {
    TablePrefix string
    TableCount  int
}

func (s *HashModSharding) GetTableName(shortURL string) string {
    h := fnv.New32a()
    h.Write([]byte(shortURL))
    hashValue := h.Sum32()
    tableIndex := hashValue % uint32(s.TableCount)
    return fmt.Sprintf("%s_%d", s.TablePrefix, tableIndex)
}

// 按时间范围分表
type TimeRangeSharding struct {
    TablePrefix string
    TimeFormat  string // 如"200601"表示按年月分表
}

func (s *TimeRangeSharding) GetTableName(accessTime time.Time) string {
    timeStr := accessTime.Format(s.TimeFormat)
    return fmt.Sprintf("%s_%s", s.TablePrefix, timeStr)
}
```

#### 数据归档策略

1. **冷热数据分离**
   - 热数据：最近3个月活跃的短链保留在主表
   - 冷数据：超过3个月不活跃的短链迁移到历史表
   - 实现方式：定期任务扫描并迁移数据

2. **TTL自动过期**
   - 为短链设置TTL（生存时间）
   - 过期后自动标记为无效，不再提供服务
   - 定期清理过期数据到归档表

3. **分区表策略**
   - 使用MySQL分区表按时间范围分区
   - 定期删除旧分区，添加新分区
   - 简化数据归档和清理流程

**归档任务示例（Go）**
```go
func ArchiveExpiredShortURLs(db *sql.DB) error {
    // 开启事务
    tx, err := db.Begin()
    if err != nil {
        return err
    }
    defer tx.Rollback()
    
    // 查询需要归档的数据
    rows, err := tx.Query(
        "SELECT id, short_url, long_url, user_id, created_at, expired_at, status, source, description " +
        "FROM t_short_url " +
        "WHERE (expired_at IS NOT NULL AND expired_at < NOW()) OR " +
        "(created_at < DATE_SUB(NOW(), INTERVAL 3 MONTH) AND " +
        "id NOT IN (SELECT short_url_id FROM t_access_stats WHERE access_time > DATE_SUB(NOW(), INTERVAL 3 MONTH)))",
    )
    if err != nil {
        return err
    }
    defer rows.Close()
    
    // 插入归档表
    stmt, err := tx.Prepare(
        "INSERT INTO t_short_url_archive " +
        "(id, short_url, long_url, user_id, created_at, expired_at, status, source, description, archived_at) " +
        "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, NOW())",
    )
    if err != nil {
        return err
    }
    defer stmt.Close()
    
    // 处理每一行数据
    var count int
    for rows.Next() {
        var id, userId sql.NullInt64
        var shortURL, longURL, source, description sql.NullString
        var createdAt, expiredAt sql.NullTime
        var status sql.NullInt32
        
        err := rows.Scan(&id, &shortURL, &longURL, &userId, &createdAt, &expiredAt, &status, &source, &description)
        if err != nil {
            return err
        }
        
        // 插入归档表
        _, err = stmt.Exec(id, shortURL, longURL, userId, createdAt, expiredAt, status, source, description)
        if err != nil {
            return err
        }
        
        count++
    }
    
    // 删除已归档的数据
    if count > 0 {
        _, err = tx.Exec(
            "DELETE FROM t_short_url " +
            "WHERE (expired_at IS NOT NULL AND expired_at < NOW()) OR " +
            "(created_at < DATE_SUB(NOW(), INTERVAL 3 MONTH) AND " +
            "id NOT IN (SELECT short_url_id FROM t_access_stats WHERE access_time > DATE_SUB(NOW(), INTERVAL 3 MONTH)))",
        )
        if err != nil {
            return err
        }
    }
    
    // 提交事务
    return tx.Commit()
}
```

### 3.4 缓存策略

#### 多级缓存设计

1. **本地缓存（进程内缓存）**
   - 使用内存缓存库如BigCache或Freecache
   - 缓存最热门的短链（如Top 1000）
   - 优点：访问速度最快，无网络开销
   - 缺点：容量有限，多实例间不共享

2. **分布式缓存（Redis）**
   - 缓存所有活跃短链映射关系
   - 采用LRU/LFU淘汰策略
   - 优点：容量大，多实例共享
   - 缺点：有网络开销

3. **CDN缓存**
   - 对于超高频访问的短链，配置CDN缓存
   - 通过设置Cache-Control头控制缓存时间
   - 优点：全球加速，减轻源站压力
   - 缺点：统计数据不实时，更新延迟

#### 缓存策略实现

**Cache-Aside模式（Go实现）**
```go
type URLCache struct {
    localCache  *freecache.Cache
    redisClient *redis.Client
    db          *sql.DB
}

func NewURLCache() *URLCache {
    return &URLCache{
        localCache:  freecache.NewCache(100 * 1024 * 1024), // 100MB
        redisClient: redis.NewClient(&redis.Options{
            Addr: "localhost:6379",
        }),
        db: nil, // 初始化数据库连接
    }
}

// 获取长URL
func (c *URLCache) GetLongURL(shortURL string) (string, error) {
    // 1. 查询本地缓存
    if val, err := c.localCache.Get([]byte(shortURL)); err == nil {
        return string(val), nil
    }
    
    // 2. 查询Redis缓存
    val, err := c.redisClient.Get(context.Background(), "url:"+shortURL).Result()
    if err == nil {
        // 命中Redis缓存，回填本地缓存
        c.localCache.Set([]byte(shortURL), []byte(val), 3600) // 1小时过期
        return val, nil
    }
    
    if err != redis.Nil {
        // Redis错误，不是键不存在
        return "", err
    }
    
    // 3. 查询数据库
    var longURL string
    err = c.db.QueryRow("SELECT long_url FROM t_short_url WHERE short_url = ? AND status = 1", shortURL).Scan(&longURL)
    if err != nil {
        if err == sql.ErrNoRows {
            // 数据不存在，缓存空结果防止缓存穿透
            c.redisClient.Set(context.Background(), "url:"+shortURL, "", time.Minute*10)
            return "", fmt.Errorf("short URL not found")
        }
        return "", err
    }
    
    // 回填Redis缓存，设置随机过期时间防止缓存雪崩
    expiration := time.Hour*24 + time.Duration(rand.Intn(3600))*time.Second
    c.redisClient.Set(context.Background(), "url:"+shortURL, longURL, expiration)
    
    // 回填本地缓存
    c.localCache.Set([]byte(shortURL), []byte(longURL), 3600) // 1小时过期
    
    return longURL, nil
}
```

#### 缓存一致性保障

1. **更新策略**
   - 先更新数据库，再删除缓存
   - 使用消息队列确保缓存最终一致性

2. **防止缓存穿透**
   - 对不存在的短链进行空值缓存
   - 使用布隆过滤器快速判断短链是否存在

3. **防止缓存雪崩**
   - 设置随机过期时间
   - 热点数据永不过期，通过后台任务更新

4. **防止缓存击穿**
   - 使用互斥锁或分布式锁
   - 单线程更新缓存，其他线程等待或返回旧值

**布隆过滤器实现（Go）**
```go
import (
    "github.com/bits-and-blooms/bloom/v3"
)

type ShortURLFilter struct {
    filter    *bloom.BloomFilter
    db        *sql.DB
    mutex     sync.RWMutex
    lastRebuild time.Time
}

func NewShortURLFilter(db *sql.DB) *ShortURLFilter {
    filter := &ShortURLFilter{
        filter: bloom.NewWithEstimates(10000000, 0.01), // 1千万个元素，1%误判率
        db:     db,
    }
    filter.Rebuild()
    return filter
}

// 重建布隆过滤器
func (f *ShortURLFilter) Rebuild() error {
    f.mutex.Lock()
    defer f.mutex.Unlock()
    
    // 创建新的布隆过滤器
    newFilter := bloom.NewWithEstimates(10000000, 0.01)
    
    // 分批查询所有短链
    offset := 0
    batchSize := 10000
    for {
        rows, err := f.db.Query(
            "SELECT short_url FROM t_short_url WHERE status = 1 LIMIT ? OFFSET ?", 
            batchSize, offset,
        )
        if err != nil {
            return err
        }
        
        count := 0
        for rows.Next() {
            var shortURL string
            if err := rows.Scan(&shortURL); err != nil {
                rows.Close()
                return err
            }
            newFilter.Add([]byte(shortURL))
            count++
        }
        rows.Close()
        
        if count < batchSize {
            break
        }
        offset += batchSize
    }
    
    // 替换旧的布隆过滤器
    f.filter = newFilter
    f.lastRebuild = time.Now()
    return nil
}

// 检查短链是否可能存在
func (f *ShortURLFilter) MayExist(shortURL string) bool {
    f.mutex.RLock()
    defer f.mutex.RUnlock()
    return f.filter.Test([]byte(shortURL))
}

// 添加新短链到过滤器
func (f *ShortURLFilter) Add(shortURL string) {
    f.mutex.Lock()
    defer f.mutex.Unlock()
    f.filter.Add([]byte(shortURL))
}
```

### 3.5 存储方案

#### 存储层设计

1. **关系型数据库（MySQL）**
   - 存储短链映射关系和基本元数据
   - 支持事务和复杂查询
   - 主从架构提高可用性

2. **时序数据库（InfluxDB/TimescaleDB）**
   - 存储访问统计数据
   - 高效处理时间序列数据
   - 支持聚合和降采样

3. **对象存储（MinIO/S3）**
   - 存储访问日志和原始数据
   - 成本低，容量大
   - 支持生命周期管理

#### 数据一致性保障

1. **主从复制**
   - MySQL主从复制确保数据备份
   - 半同步复制提高数据可靠性
   - 读写分离提高性能

2. **数据备份**
   - 定时全量备份
   - 实时增量备份（binlog）
   - 跨区域备份防止区域性故障

3. **数据校验**
   - 定期校验主从数据一致性
   - 使用校验和验证数据完整性
   - 自动修复不一致数据

**MySQL主从配置示例**
```
# 主库配置 (my.cnf)
server-id = 1
log_bin = mysql-bin
binlog_format = ROW
binlog_row_image = FULL
sync_binlog = 1
innodb_flush_log_at_trx_commit = 1

# 从库配置 (my.cnf)
server-id = 2
relay_log = mysql-relay-bin
read_only = ON
slave_compressed_protocol = 1
```

**数据备份脚本（Shell）**
```bash
#!/bin/bash

# 配置
DB_USER="root"
DB_PASS="password"
DB_NAME="shorturl_db"
BACKUP_DIR="/backup/mysql"
DATE=$(date +"%Y%m%d%H%M")

# 创建备份目录
mkdir -p ${BACKUP_DIR}

# 全量备份
mysqldump -u${DB_USER} -p${DB_PASS} --single-transaction --routines --triggers --events ${DB_NAME} > ${BACKUP_DIR}/${DB_NAME}_${DATE}.sql

# 压缩备份文件
gzip ${BACKUP_DIR}/${DB_NAME}_${DATE}.sql

# 删除7天前的备份
find ${BACKUP_DIR} -name "${DB_NAME}_*.sql.gz" -mtime +7 -delete

# 备份binlog
mysql -u${DB_USER} -p${DB_PASS} -e "FLUSH BINARY LOGS;"
mysql -u${DB_USER} -p${DB_PASS} -e "PURGE BINARY LOGS BEFORE DATE_SUB(NOW(), INTERVAL 3 DAY);"

echo "Backup completed: ${BACKUP_DIR}/${DB_NAME}_${DATE}.sql.gz"
```